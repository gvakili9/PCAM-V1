{"cells":[{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","PCAM Model Pipeline Simulation (Python 3) - RESOURCE CONSTRAINED VERSION\n","\n","PHASE A: AUTOMATED DATA GENERATION (Synthetic Training Corpus Creation)\n","PHASE B: LLM FINE-TUNING EXECUTION (LoRA/SFT - CPU/Free Quota Execution)\n","PHASE C: CULTURAL ALIGNMENT EXECUTION (DPO - Conceptual Setup)\n","\n","This notebook adapts the PCAM pipeline to run successfully on a standard CPU runtime\n","by using a minimal model, demonstrating the required academic steps without using GPU quota.\n","\n","REQUIREMENTS:\n","1. CPU runtime environment (NO GPU REQUIRED).\n","2. A working Gemini API Key (replace 'YOUR_GEMINI_API_KEY' below).\n","\"\"\"\n","\n","# --- 1. Installation of Required Libraries ---\n","!pip install --upgrade pip\n","!pip install numpy\n","# NOTE: We keep transformers/peft/trl for conceptual configuration, but the model size is minimal\n","!pip install requests beautifulsoup4 parsivar pandas transformers accelerate peft trl\n","!pip install google-genai huggingface_hub\n","\n","import requests\n","from parsivar import Normalizer, Tokenizer\n","import pandas as pd\n","import json\n","import random\n","import time\n","from urllib.parse import urljoin\n","from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n","from peft import LoraConfig, get_peft_model\n","from trl import SFTTrainer, DPOTrainer\n","from datasets import Dataset\n","import torch\n","import os\n","from tqdm import tqdm\n","from huggingface_hub import notebook_login # Import for authentication\n","\n","# --- CRITICAL CONFIGURATION ---\n","GEMINI_API_KEY = \"AIzaSyATNpKIY_NAYT38szXMAsU2UGBdlUBC9Aw\" # <<<<< REPLACE THIS WITH YOUR KEY >>>>>\n","NUM_STORIES_TO_GENERATE = 500  # *** Target for robust training (Data generation runs fast) ***\n","OUTPUT_SFT_DATA_FILE = \"pcam_sft_corpus.json\"\n","OUTPUT_DPO_DATA_FILE = \"pcam_dpo_preferences.json\"\n","# FIX: Switched to a tiny, open-access model for CPU training demonstration\n","MODEL_NAME = \"EleutherAI/gpt-neo-125M\"\n","# ------------------------------\n","\n","# Initialize Farsi NLP Tools\n","normalizer = Normalizer()\n","tokenizer = Tokenizer()\n","\n","# --- HUGGING FACE AUTHENTICATION STEP ---\n","# NOTE: Still needed to download model weights, but GPT-Neo 125M is open. Run anyway for practice.\n","print(\"--- HUGGING FACE AUTHENTICATION ---\")\n","print(\"Authenticating, though GPT-Neo 125M should be open access.\")\n","# notebook_login() # Commented out to avoid interactive prompt, run manually if needed\n","# ----------------------------------------\n","\n","\n","# --- PHASE A: AUTOMATED DATA GENERATION (Synthetic Training Corpus Creation) ---\n","\n","print(\"--- PHASE A: AUTOMATED DATA GENERATION (SYNTHETIC CORPUS) ---\")\n","\n","# Define the structured output schema (same as before)\n","PCAM_SCHEMA = {\n","    \"type\": \"OBJECT\",\n","    \"properties\": {\n","        \"title_en\": {\"type\": \"STRING\"},\n","        \"title_fa\": {\"type\": \"STRING\"},\n","        \"cultural_footnote\": {\"type\": \"STRING\"},\n","        \"story_pairs\": {\n","            \"type\": \"ARRAY\",\n","            \"items\": {\n","                \"type\": \"OBJECT\",\n","                \"properties\": {\n","                    \"en\": {\"type\": \"STRING\"},\n","                    \"fa\": {\"type\": \"STRING\"}\n","                }\n","            }\n","        }\n","    }\n","}\n","\n","# Expanded list of potential story inputs for diversification (Same as before)\n","STORY_INPUT_TEMPLATES = [\n","    (\"Nowruz/Haft-Seen\", \"early_reader\", \"respect_family\", \"A little girl finding the missing 'Sabzeh' with her horse Raksh.\"),\n","    (\"Nowruz/Haft-Seen\", \"preschool\", \"kindness_generosity\", \"Two brothers learning the meaning of the *Samanu* and sharing it.\"),\n","    (\"Nowruz/Haft-Seen\", \"chapter_book\", \"bravery_humility\", \"A young boy's journey to prepare a *Haft-Seen* item for an elderly neighbor.\"),\n","    (\"Yalda Night/Shahnameh\", \"early_reader\", \"wisdom_patience\", \"A simplified tale of Rostam learning patience from Raksh on Yalda Night.\"),\n","    (\"Yalda Night/Shahnameh\", \"preschool\", \"family_unity\", \"Pomegranate seeds telling a story of how family stays close in the longest night.\"),\n","    (\"Everyday/Garden\", \"preschool\", \"kindness_generosity\", \"A story about a nightingale helping a flower in a Persian garden (Gol-o-Morgh).\"),\n","    (\"Everyday/Garden\", \"early_reader\", \"respect_family\", \"A child who visits their grandmother's saffron farm and learns about hard work.\"),\n","]\n","\n","def generate_pcam_story_via_api(instruction, input_topic):\n","    \"\"\"Calls the Gemini API to generate one structured, aligned story.\"\"\"\n","\n","    api_url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key={GEMINI_API_KEY}\"\n","\n","    payload = {\n","        \"contents\": [{\"parts\": [{\"text\": f\"Generate story about: {input_topic}\"}]}],\n","        \"systemInstruction\": {\"parts\": [{\"text\": instruction}]},\n","        \"generationConfig\": {\n","            \"responseMimeType\": \"application/json\",\n","            \"responseSchema\": PCAM_SCHEMA\n","        }\n","    }\n","\n","    try:\n","        response = requests.post(api_url, json=payload, timeout=30)\n","        response.raise_for_status()\n","        result = response.json()\n","\n","        text = result['candidates'][0]['content']['parts'][0]['text']\n","        story_json = json.loads(text)\n","\n","        # Convert the generated JSON structure into the flat format required for SFTTrainer\n","        formatted_output = f\"###Instruction: {instruction} ###Input: {input_topic} ###Output: {json.dumps(story_json, ensure_ascii=False)}\"\n","        return formatted_output\n","\n","    except Exception as e:\n","        return None\n","\n","\n","# The main loop for data generation\n","pcam_sft_data = [] # Data for Supervised Fine-Tuning (SFT)\n","pcam_dpo_data = [] # Data for DPO Alignment (requires preference)\n","\n","# Check if data already exists, if so, load it and skip generation\n","if os.path.exists(OUTPUT_SFT_DATA_FILE):\n","    print(f\"\\n[INFO] Data files found. Skipping API generation and loading existing data.\")\n","    with open(OUTPUT_SFT_DATA_FILE, 'r', encoding='utf-8') as f:\n","        # Load only a tiny subset for fast, zero-quota training\n","        pcam_sft_data = json.load(f)[:20] # FIX: Load only 20 stories for quick CPU test\n","    with open(OUTPUT_DPO_DATA_FILE, 'r', encoding='utf-8') as f:\n","        pcam_dpo_data = json.load(f)[:10] # FIX: Load only 10 pairs for quick CPU test\n","    print(f\"Loaded {len(pcam_sft_data)} SFT stories and {len(pcam_dpo_data)} DPO pairs for CPU training.\")\n","\n","else:\n","    # --- Execute Generation if data is missing (omitted for brevity) ---\n","    print(\"\\n[INFO] Data files missing. Please run Phase A first to generate data.\")\n","\n","\n","# --- PHASE B: LINGUISTIC INJECTION (SFT/LoRA) ---\n","\n","print(\"\\n--- PHASE B: LINGUISTIC INJECTION (SFT/LoRA EXECUTION) - CPU MODE ---\")\n","\n","# Step 1: Load Data into HuggingFace Dataset format\n","if len(pcam_sft_data) == 0:\n","    print(\"[ERROR] Cannot start training. Dataset is empty.\")\n","    sft_dataset = None\n","else:\n","    sft_dataset = Dataset.from_pandas(pd.DataFrame(pcam_sft_data))\n","\n","if sft_dataset:\n","    # Step 2: Load Model and Tokenizer (CPU MODE)\n","    try:\n","        print(f\"Loading CPU-optimized base model: {MODEL_NAME}\")\n","        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n","        tokenizer.pad_token = tokenizer.eos_token\n","\n","        # Load the model directly without quantization (necessary for CPU)\n","        model = AutoModelForCausalLM.from_pretrained(\n","            MODEL_NAME,\n","            torch_dtype=torch.float32, # CPU standard precision\n","            device_map=\"cpu\", # Explicitly map to CPU\n","            trust_remote_code=True,\n","        )\n","\n","    except Exception as e:\n","        print(f\"[CRITICAL ERROR] Model loading failed. Error: {e}\")\n","        model = None\n","\n","    if model:\n","        # Step 3: Configure LoRA (PEFT)\n","        lora_config = LoraConfig(\n","            r=8, lora_alpha=16, target_modules=[\"q_proj\", \"v_proj\"], # Reduced rank for tiny model\n","            lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\",\n","        )\n","\n","        # Step 4: Define Training Arguments (CPU-Specific)\n","        training_args = TrainingArguments(\n","            output_dir=\"./pcam_sft_adapters_cpu\",\n","            num_train_epochs=1,\n","            per_device_train_batch_size=1, # Very small batch size for memory\n","            gradient_accumulation_steps=1,\n","            optim=\"adamw_torch\", # CPU-friendly optimizer\n","            logging_steps=1,\n","            learning_rate=2e-5, # Very small learning rate\n","            fp16=False, # Disable mixed precision (CPU incompatibility)\n","            bf16=False,\n","            save_strategy=\"epoch\",\n","            push_to_hub=False,\n","            report_to=\"none\"\n","        )\n","\n","        # Step 5: Initialize and Start SFT Training\n","        print(\"\\nStarting Supervised Fine-Tuning (SFT) Trainer on CPU...\")\n","\n","        trainer_sft = SFTTrainer(\n","            model=model,\n","            train_dataset=sft_dataset,\n","            peft_config=lora_config,\n","            args=training_args,\n","        )\n","\n","        # Start the training loop\n","        trainer_sft.train()\n","        trainer_sft.model.save_pretrained(\"./pcam_sft_adapters_cpu\")\n","        print(\"\\n[PHASE B COMPLETE] LoRA adapters (PCAM SFT weights) saved to './pcam_sft_adapters_cpu'\")\n","\n","        # Keep the trained model instance for DPO initialization\n","        SFT_MODEL = trainer_sft.model\n","\n","\n","# --- PHASE C: CULTURAL ALIGNMENT (DPO) - CONCEPTUAL EXECUTION ---\n","\n","print(\"\\n--- PHASE C: CULTURAL ALIGNMENT (DPO EXECUTION) - CPU MODE CONCEPTUAL ---\")\n","\n","if 'SFT_MODEL' in locals() and len(pcam_dpo_data) > 0:\n","    try:\n","        print(f\"Loaded {len(pcam_dpo_data)} preference pairs for DPO.\")\n","\n","        # Load DPO preference dataset\n","        dpo_dataset = Dataset.from_pandas(pd.DataFrame(pcam_dpo_data))\n","\n","        # Format the DPO data structure expected by DPOTrainer\n","        dpo_dataset = dpo_dataset.rename_columns({\n","            \"prompt\": \"prompt\",\n","            \"chosen\": \"chosen\",\n","            \"rejected\": \"rejected\"\n","        })\n","\n","        # Step 2: Define DPO Training Arguments (CPU-Specific)\n","        dpo_args = TrainingArguments(\n","            output_dir=\"./pcam_dpo_adapters_cpu\",\n","            num_train_epochs=1,\n","            per_device_train_batch_size=1, # Very small batch size for CPU\n","            gradient_accumulation_steps=1,\n","            learning_rate=1e-6, # Very small learning rate for DPO on CPU\n","            logging_steps=1,\n","            save_strategy=\"epoch\",\n","            push_to_hub=False,\n","            remove_unused_columns=False,\n","            fp16=False, bf16=False,\n","            report_to=\"none\"\n","        )\n","\n","        # Step 3: Initialize and Start DPOTrainer\n","        print(\"\\nStarting Direct Preference Optimization (DPO) Trainer on CPU...\")\n","\n","        dpo_trainer = DPOTrainer(\n","            model=SFT_MODEL,\n","            args=dpo_args,\n","            beta=0.1,\n","            train_dataset=dpo_dataset,\n","            tokenizer=tokenizer,\n","            max_length=256,\n","            max_target_length=128,\n","            max_prompt_length=128,\n","        )\n","\n","        dpo_trainer.train()\n","        dpo_trainer.model.save_pretrained(\"./pcam_final_adapters_cpu\")\n","        print(\"\\n[PHASE C COMPLETE] FINAL PCAM adapters (Cultural Alignment) saved to './pcam_final_adapters_cpu'\")\n","\n","    except Exception as e:\n","        print(f\"[ERROR] DPO Execution Failed. Error: {e}\")\n","else:\n","    print(\"\\n[SKIP] DPO phase skipped because the SFT Model (Phase B) failed or DPO dataset is empty.\")\n","\n","print(\"\\n--- PROJECT NEXT STEPS ---\")\n","print(\"1. Discuss the trade-off between speed (GPU) and accessibility (CPU) in the project report.\")\n","print(\"2. Test the conceptually fine-tuned model against the Human Alignment Score (H-Score) rubric.\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n","Requirement already satisfied: parsivar in /usr/local/lib/python3.12/dist-packages (0.2.3.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n","Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.25.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n","Requirement already satisfied: nltk>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from parsivar) (3.9.1)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n","Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl) (4.0.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.6.6->parsivar) (8.3.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.6.6->parsivar) (1.5.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n","Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.52.0)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n","Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n","Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.43.0)\n","Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n","Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.12.3)\n","Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n","Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (9.1.2)\n","Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n","Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (6.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.11.12)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n","--- HUGGING FACE AUTHENTICATION ---\n","Authenticating, though GPT-Neo 125M should be open access.\n","--- PHASE A: AUTOMATED DATA GENERATION (SYNTHETIC CORPUS) ---\n","\n","[INFO] Data files found. Skipping API generation and loading existing data.\n","Loaded 1 SFT stories and 0 DPO pairs for CPU training.\n","\n","--- PHASE B: LINGUISTIC INJECTION (SFT/LoRA EXECUTION) - CPU MODE ---\n","Loading CPU-optimized base model: EleutherAI/gpt-neo-125M\n","\n","Starting Supervised Fine-Tuning (SFT) Trainer on CPU...\n"]},{"output_type":"display_data","data":{"text/plain":["Adding EOS to train dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f94651d0ef8499794a0e38d99999575"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Tokenizing train dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c488c755a824833ba87ecf9f58613a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Truncating train dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13f4de3de1de424c9d8125dce35910cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 00:01, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.467100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","[PHASE B COMPLETE] LoRA adapters (PCAM SFT weights) saved to './pcam_sft_adapters_cpu'\n","\n","--- PHASE C: CULTURAL ALIGNMENT (DPO EXECUTION) - CPU MODE CONCEPTUAL ---\n","\n","[SKIP] DPO phase skipped because the SFT Model (Phase B) failed or DPO dataset is empty.\n","\n","--- PROJECT NEXT STEPS ---\n","1. Discuss the trade-off between speed (GPU) and accessibility (CPU) in the project report.\n","2. Test the conceptually fine-tuned model against the Human Alignment Score (H-Score) rubric.\n"]}],"execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1f94651d0ef8499794a0e38d99999575","15bd215a0dc54ac79b4fc5a61a84e580","6b8aa86564ac459c9de5f5ae20155390","0014a02a44464aa4b25093ed50a1cfb7","eb43213d48b8486fa28bbb956c059673","45fc628a20cd46afb9a77f929345e8cb","bfd4a2d86664488a9bd51e70068f3fc5","3f7993083ef64957b742f73ac0a05ef6","358c5927cb1a480593f176778a3e7fcf","943760be72b746aa89f346b031bb0d87","c04642b8305147bfa06d3027126c00f9","5c488c755a824833ba87ecf9f58613a7","b7fefbfc200149a189d0e8a04e6a22cb","3b5103fa11e24e1ca3b635388a9bd0b7","becc1f5a4ae9431a9ee85ea4afc91cfe","76902c01b1034b3ca01331bd1e1fa504","a4b9fe5f17eb417eb2bfe1facaa374ef","dfc1edc1b64944f9832718f64f5d42a4","6ae668cd98354e779e0bfed57ad30530","adc54d6c765e45e38463ac52ecba2d78","a10f7a73e3ae45ac9e82346112652b33","79c1ba4d4db24b3fb7f68f46ffa3869e","13f4de3de1de424c9d8125dce35910cf","a64b0365d63540508a7d006680e8426f","5cfcdcabc1e34533a2c91fbd6064ddfd","13aaee6879c74296bf627287559df5cd","4d4831464fe247989788660c1d117c69","1b91b7fb13e249728e3c17a430e7da7e","40d01a40bf8942e6b125d679126734e7","2fa9d4c223114def991c8006680cc21a","539e68db02974263a9fa01270c81a097","9c8f6aae887d4cdeb197c2f7d97dbd2a","afe74063b76f4cdfb2870fa8c0a0113e"]},"id":"DJLVvQ0OvS1-","outputId":"01428242-2fdd-49a5-a8d5-f91c78c9fab8","executionInfo":{"status":"ok","timestamp":1765080238223,"user_tz":300,"elapsed":28196,"user":{"displayName":"Gelareh Vakili","userId":"05550258640247855554"}}}}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1f94651d0ef8499794a0e38d99999575":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_15bd215a0dc54ac79b4fc5a61a84e580","IPY_MODEL_6b8aa86564ac459c9de5f5ae20155390","IPY_MODEL_0014a02a44464aa4b25093ed50a1cfb7"],"layout":"IPY_MODEL_eb43213d48b8486fa28bbb956c059673"}},"15bd215a0dc54ac79b4fc5a61a84e580":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45fc628a20cd46afb9a77f929345e8cb","placeholder":"​","style":"IPY_MODEL_bfd4a2d86664488a9bd51e70068f3fc5","value":"Adding EOS to train dataset: 100%"}},"6b8aa86564ac459c9de5f5ae20155390":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f7993083ef64957b742f73ac0a05ef6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_358c5927cb1a480593f176778a3e7fcf","value":1}},"0014a02a44464aa4b25093ed50a1cfb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_943760be72b746aa89f346b031bb0d87","placeholder":"​","style":"IPY_MODEL_c04642b8305147bfa06d3027126c00f9","value":" 1/1 [00:00&lt;00:00, 82.25 examples/s]"}},"eb43213d48b8486fa28bbb956c059673":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45fc628a20cd46afb9a77f929345e8cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfd4a2d86664488a9bd51e70068f3fc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f7993083ef64957b742f73ac0a05ef6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"358c5927cb1a480593f176778a3e7fcf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"943760be72b746aa89f346b031bb0d87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c04642b8305147bfa06d3027126c00f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c488c755a824833ba87ecf9f58613a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7fefbfc200149a189d0e8a04e6a22cb","IPY_MODEL_3b5103fa11e24e1ca3b635388a9bd0b7","IPY_MODEL_becc1f5a4ae9431a9ee85ea4afc91cfe"],"layout":"IPY_MODEL_76902c01b1034b3ca01331bd1e1fa504"}},"b7fefbfc200149a189d0e8a04e6a22cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4b9fe5f17eb417eb2bfe1facaa374ef","placeholder":"​","style":"IPY_MODEL_dfc1edc1b64944f9832718f64f5d42a4","value":"Tokenizing train dataset: 100%"}},"3b5103fa11e24e1ca3b635388a9bd0b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ae668cd98354e779e0bfed57ad30530","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adc54d6c765e45e38463ac52ecba2d78","value":1}},"becc1f5a4ae9431a9ee85ea4afc91cfe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a10f7a73e3ae45ac9e82346112652b33","placeholder":"​","style":"IPY_MODEL_79c1ba4d4db24b3fb7f68f46ffa3869e","value":" 1/1 [00:00&lt;00:00, 60.28 examples/s]"}},"76902c01b1034b3ca01331bd1e1fa504":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4b9fe5f17eb417eb2bfe1facaa374ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfc1edc1b64944f9832718f64f5d42a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ae668cd98354e779e0bfed57ad30530":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adc54d6c765e45e38463ac52ecba2d78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a10f7a73e3ae45ac9e82346112652b33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79c1ba4d4db24b3fb7f68f46ffa3869e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13f4de3de1de424c9d8125dce35910cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a64b0365d63540508a7d006680e8426f","IPY_MODEL_5cfcdcabc1e34533a2c91fbd6064ddfd","IPY_MODEL_13aaee6879c74296bf627287559df5cd"],"layout":"IPY_MODEL_4d4831464fe247989788660c1d117c69"}},"a64b0365d63540508a7d006680e8426f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b91b7fb13e249728e3c17a430e7da7e","placeholder":"​","style":"IPY_MODEL_40d01a40bf8942e6b125d679126734e7","value":"Truncating train dataset: 100%"}},"5cfcdcabc1e34533a2c91fbd6064ddfd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fa9d4c223114def991c8006680cc21a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_539e68db02974263a9fa01270c81a097","value":1}},"13aaee6879c74296bf627287559df5cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c8f6aae887d4cdeb197c2f7d97dbd2a","placeholder":"​","style":"IPY_MODEL_afe74063b76f4cdfb2870fa8c0a0113e","value":" 1/1 [00:00&lt;00:00, 85.86 examples/s]"}},"4d4831464fe247989788660c1d117c69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b91b7fb13e249728e3c17a430e7da7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40d01a40bf8942e6b125d679126734e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fa9d4c223114def991c8006680cc21a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"539e68db02974263a9fa01270c81a097":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c8f6aae887d4cdeb197c2f7d97dbd2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afe74063b76f4cdfb2870fa8c0a0113e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}